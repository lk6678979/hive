## 笔记
## hive on spark 在CDH的hive配置中搜索spark 配置完重启
### 1.创建数据库
* 创建数据库会在hdfs的hive目录(默认/user/hive/warehouse)下创建一个文件夹，名字为：`数据库名.db`，这里是testhive.db
### 2. 建内部表
* 该操作会在hdfs中数据库目录下创建一个同名的文件夹
### 3. 使用load往内部表中加载数据
* 需要提前准备数据文件
* load方法会将源文件复制一份到表所在的hdfs目录中，不会直接使用源文件
* load加载数据文件，会在表目录下创建和被load的文件名相同的一个文件（如果文件名冲突，会生成_copy_*的文件）
* 提交的数据，每行数字可以字段不足，不足的字段在表中int会转为null，字符串会转为空字符串，不会异常
* 如果字段无法转换成表结构中定义的数据格式，会加载为null
* 使用overwrite后，会删除hdfs表目录下所有的文件，并写入新的文件
### 4. 使用insert往内部表中加载数据
* insert方法会将源文件复制一份到表所在的hdfs目录中，不会直接使用源文件
* 会在表目录中新建一个文件存储insert的数据(不管是values还是select子查询到的数据），文件名从0开始递增，例如000000_0
### 5. 创建分区表
* 创建分区表的时候不会创建额外的目录
* 创建分区表后，在加载数据之前，需要手动去创建分区，创建分区的操作会在表的hdfs目录下创建对应的文件件，名称：分区字段=值，例如：city=beijing
### 6. 使用load往内部分区表中加载数据
* 和load到普通表一样，只不过文件操作是在表的分区目录下
* load的分区字段不能存在元数据的字段中，否则会异常
### 7. 使用insert往内部分区表中加载数据
* 和insert到普通表一样，只不过文件操作是在表的分区目录下

# 结论：要想在hive表中追加文件，只能去分区中的文件里直接追加数据，不能使用hive接口去追加
